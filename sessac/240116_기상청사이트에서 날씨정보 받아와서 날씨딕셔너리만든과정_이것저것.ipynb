{"cells":[{"cell_type":"markdown","metadata":{"id":"PcXb0oNAk0J5"},"source":["### 일자별 날씨정보 API\n","-아래사이트의 기상정보를 가져와서 dict 구조로 작성한후 json 파일로 저장하는 내용입니다.\n","-http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=Y9vZZYdTITnGhBz7r3628UaVagdVfFEt7urjSsx3ha5rmD9ohXbuD546nfVlktbIbE9G5At1lXbcXKSo%2BEYYig%3D%3D&pageNo=1&numOfRows=10&dataType=XML&dataCd=ASOS&dateCd=DAY&startDt=20230101&endDt=20231231&stnIds=108\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6948,"status":"ok","timestamp":1705380549108,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"BxcLu0DTk0J9","outputId":"70f152a5-6f96-4724-d2ac-52d554bec92d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tqdm in c:\\users\\bluecom010\\miniconda3\\envs\\openai\\lib\\site-packages (4.66.1)\n","Requirement already satisfied: colorama in c:\\users\\bluecom010\\miniconda3\\envs\\openai\\lib\\site-packages (from tqdm) (0.4.6)\n"]}],"source":["# !pip install pyOpenSSL\n","# !pip install request\n","# !pip install bs4\n","!pip install tqdm"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1705380555664,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"H91i9JVik0J-","outputId":"9ed1101c-2831-4984-a3ce-0182188494ef"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 1002223.18it/s]\n"]}],"source":["###################\n","## 참고: 프로그레스바(진행바)\n","##################\n","sum=0\n","for x in tqdm(range(1000)):\n","    sum+=x\n","\n","#밑에 셀 돌리고 이거 돌려야 에러안남 "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2Sj7VL5ek0J_"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup as bs\n","import pandas as pd\n","from tqdm import tqdm  #진행사항을 알리는 프로그레스바\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"elapsed":1188,"status":"ok","timestamp":1705380577506,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"t42gFElDk0J_","outputId":"e6a23525-c285-4ac6-e2cf-43894d4e6070"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\bluecom010\\miniconda3\\envs\\OpenAI\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n","  warnings.warn(\n"]},{"data":{"text/plain":["'365'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["########################################\n","### 전체데이터가 몇개인지 미리 알고 그 갯수를 전체데이터갯수에 넣으면 모든 자료 읽어올수 있음.\n","#######################################\n","\n","url='http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=Y9vZZYdTITnGhBz7r3628UaVagdVfFEt7urjSsx3ha5rmD9ohXbuD546nfVlktbIbE9G5At1lXbcXKSo%2BEYYig%3D%3D&pageNo=1&numOfRows=10&dataType=XML&dataCd=ASOS&dateCd=DAY&startDt=20230101&endDt=20231231&stnIds=108'\n","xml=requests.get(url)\n","soup=bs(xml.text,'html.parser')\n","totCnt=soup.totalcount.text\n","totCnt\n","#365 : totCnt에 저장된 '365'는 API 응답에서 추출한 전체 데이터 건수를 나타냅니다. \n","# 이 값은 데이터포털 API에서 기상 관측 정보를 연도 단위로 제공하고 있는 것으로 보입니다. '365'는 연간(365일) 데이터가 있는 것으로 추정됩니다."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"x1iw9Ai1k0J_"},"outputs":[],"source":["# 공공API 인증키 (부성순강사 인증키임. 본인자료는 다시 인증키 받아야함.)\n","def myUrlOpen(지점코드=108,totCnt=1,startDate='20230101',endDate='20231231'):\n","    인증키='Y9vZZYdTITnGhBz7r3628UaVagdVfFEt7urjSsx3ha5rmD9ohXbuD546nfVlktbIbE9G5At1lXbcXKSo%2BEYYig%3D%3D'\n","    지점코드=108   #서울\n","    url='http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey='\n","    url=url+인증키\n","    url=url+ '&pageNo=1&numOfRows='\n","    url=url+str(totCnt)+'&dataType=XML&dataCd=ASOS&dateCd=DAY&startDt='\n","    url=url+startDate+'&endDt='+endDate+'&stnIds='\n","    url=url+str(지점코드)\n","    print(url)\n","    return url\n","# totCnt=5하면 <item> 5개보이고 / totCnt=365하면 <item> 365개 다 보임 \n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8539,"status":"ok","timestamp":1705380764774,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"7E2eKDqJk0KA","outputId":"5483a77a-9b29-4088-ed99-ced65d9a1506"},"outputs":[{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=Y9vZZYdTITnGhBz7r3628UaVagdVfFEt7urjSsx3ha5rmD9ohXbuD546nfVlktbIbE9G5At1lXbcXKSo%2BEYYig%3D%3D&pageNo=1&numOfRows=365&dataType=XML&dataCd=ASOS&dateCd=DAY&startDt=20230101&endDt=20231231&stnIds=108\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\bluecom010\\miniconda3\\envs\\OpenAI\\Lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n","  warnings.warn(\n","1it [00:03,  3.65s/it]"]},{"name":"stdout","output_type":"stream","text":["http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=Y9vZZYdTITnGhBz7r3628UaVagdVfFEt7urjSsx3ha5rmD9ohXbuD546nfVlktbIbE9G5At1lXbcXKSo%2BEYYig%3D%3D&pageNo=1&numOfRows=365&dataType=XML&dataCd=ASOS&dateCd=DAY&startDt=20230101&endDt=20231231&stnIds=108\n"]},{"name":"stderr","output_type":"stream","text":["2it [00:04,  2.29s/it]"]},{"name":"stdout","output_type":"stream","text":["http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList?serviceKey=Y9vZZYdTITnGhBz7r3628UaVagdVfFEt7urjSsx3ha5rmD9ohXbuD546nfVlktbIbE9G5At1lXbcXKSo%2BEYYig%3D%3D&pageNo=1&numOfRows=365&dataType=XML&dataCd=ASOS&dateCd=DAY&startDt=20230101&endDt=20231231&stnIds=108\n"]},{"name":"stderr","output_type":"stream","text":["3it [00:06,  2.08s/it]\n"]}],"source":["자료=[]\n","지점리스트={'지점명':['서울','부산','제주'],\n","              '지점코드': [108,253,184]} #기상청02_지상(종관,ASOS)일자료_조회서비스_오픈API활용가이드에 지점코드 나와있음\n","jijumList,dataList,minList,maxList,rnList=[],[],[],[],[]\n","\n","for 지점명,지점코드 in tqdm(zip(지점리스트['지점명'],지점리스트['지점코드'])):\n","\n","    url=myUrlOpen(지점코드,totCnt)\n","    xml=requests.get(url) #requests.get 함수를 사용하여 API에 GET 요청을 보내고, 응답을 받아 xml 변수에 저장\n","    soup=bs(xml.text,'html.parser') #받아온 응답(XML 형식)을 BeautifulSoup을 사용하여 파싱합니다\n","                                    #'html.parser'는 HTML 및 XML 문서를 파싱하는 데 사용되는 파서입니다. \n","    data=soup.find_all('item') #파싱된 HTML 문서에서 'item' 태그를 가진 모든 요소를 찾아 리스트로 반환합니다.\n","\n","#파싱 : 구조화되지 않은 데이터를 읽고 그것을 분석 가능한 형태로 변환하는 과정\n","#       예를 들어, 웹 페이지의 HTML 문서에서 특정 태그에 있는 데이터를 추출하거나, XML 형식의 데이터에서 원하는 요소를 선택하는 것이 파싱의 일부입니다. \n","#       BeautifulSoup과 같은 라이브러리는 파싱을 쉽게 수행할 수 있도록 도와주는 도구 중 하나입니다.\n","\n","    for item in data:\n","        jijum=지점명\n","        date=item.find('tm').text\n","        min=item.find('minta').text\n","        max=item.find('maxta').text\n","        rn=item.find('sumrn').text\n","\n","        jijumList.append(jijum) ;dataList.append(date) ; maxList.append(max); minList.append(min) ; rnList.append(rn)\n","\n","dataList=dict({'j':jijumList,\n","          'd':dataList,\n","          'm':maxList,\n","          'n':minList,\n","          'r':rnList})\n","\n","# print(dataList)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1705381076834,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"wRHu5y3Tk0KA","outputId":"50abca96-74cc-4f4b-fdf5-7d52a35c29f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['서울', '부산', '제주']\n"]},{"data":{"text/plain":["'서울_부산_제주'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["print(지점리스트['지점명'])\n","fileName='_'.join(지점리스트['지점명'])   # 파일명으로 사용하기 위하여 '서울_부산_제주'변수 저장\n","fileName"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":388},"executionInfo":{"elapsed":304,"status":"error","timestamp":1705381230098,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"FsIRpUS8k0KB","outputId":"57161bdf-5157-4639-8c78-73c0900bd12d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>j</th>\n","      <th>d</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>r</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1090</th>\n","      <td>제주</td>\n","      <td>2023-12-27</td>\n","      <td>6.8</td>\n","      <td>-2.8</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1091</th>\n","      <td>제주</td>\n","      <td>2023-12-28</td>\n","      <td>4.4</td>\n","      <td>-1.7</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1092</th>\n","      <td>제주</td>\n","      <td>2023-12-29</td>\n","      <td>4.6</td>\n","      <td>-1.5</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1093</th>\n","      <td>제주</td>\n","      <td>2023-12-30</td>\n","      <td>2.1</td>\n","      <td>-0.9</td>\n","      <td>13.1</td>\n","    </tr>\n","    <tr>\n","      <th>1094</th>\n","      <td>제주</td>\n","      <td>2023-12-31</td>\n","      <td>4.3</td>\n","      <td>0.6</td>\n","      <td>4.7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       j           d    m     n     r\n","1090  제주  2023-12-27  6.8  -2.8      \n","1091  제주  2023-12-28  4.4  -1.7      \n","1092  제주  2023-12-29  4.6  -1.5      \n","1093  제주  2023-12-30  2.1  -0.9  13.1\n","1094  제주  2023-12-31  4.3   0.6   4.7"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["#########################3\n","## 판다스로제작후 저장\n","#########################\n","df=pd.DataFrame(dataList)\n","df.to_csv('c:/data/weather/날씨_'+fileName+'.csv', encoding='utf-8',index=False)\n","df.tail() #마지막 5행 출력 "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"executionInfo":{"elapsed":313,"status":"error","timestamp":1705381251193,"user":{"displayName":"Dream","userId":"04779320850850108597"},"user_tz":-540},"id":"d4sUwMRDk0KB","outputId":"c3229d33-7b48-47af-cdb7-e8a41c42b451"},"outputs":[],"source":["################\n","### json 파일로 저장\n","##################\n","import json\n","with open('c:/data/weather/날씨_'+fileName+'.json', 'w', encoding='utf-8') as f :\n","\tjson.dump(dataList, f, indent='\\t',ensure_ascii=False)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"OpenAI","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":0}
